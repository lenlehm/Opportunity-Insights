{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET CREATION\n",
    "\n",
    "Unfortunately, the dataset I will work with does not come as one already done dataset - as it is mostly usual in Data Science projects. <br /> \n",
    "To get the sheer experience of how a normal Data Science job looks like I also wanted to dive into this issue. By experience I can tell that this takes a shit ton of time - like almost 80% - of preparing the data. <br /> \n",
    "Since the data usually shares the same countries and lists mostly the same years of the recording I used this as a primary key where I connect the datapoints with each other. <br /> \n",
    "However, the  countries are listed in rows along with the year of the recording - I want to have a final dataset that looks like follows: <br /> \n",
    "\n",
    "|Country | Afghanistan | Albania | ... | Zimbabwe | \n",
    "| ----- | ----------  | ------ | ----- | ------- | \n",
    "|Alcohol consumption [l] | 0.2 | 2.4 | ... | 0.01 |\n",
    "|Human Develpment Index (HDI) | 0.1 | 0.15 | ... | 0.1 | \n",
    "|... | ... | ... | ... | ... |\n",
    "|Healthcare Expenditure [$] | 13.322 | 15.211 | ... | 1.039 |\n",
    "\n",
    "Thus, I have to transpose each of the countries and record each of the years as seperate entry in the dataset. <br /> \n",
    "\n",
    "All the data is [publicly available](https://ourworldindata.org), and this source is trusted by many notorious companies such as Vox, The Ney York times and even the top universities of this world like MIT, Oxford, Stanford. <br /> \n",
    "Hence, I assume that this data is rather based on actual recording from the respective country. <br /> \n",
    "Even the United Nation published their records in this page and I bet that these folks do some amazing work, which we can trust. <br />\n",
    "\n",
    "\n",
    "But now let's not waste too much with the explaination part and go straight into how I merged the datafiles to one huge on. <br /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the preprocessing necessities with renaming the columns and dropping the ones we are not interested in, i.e. continents aggregated stuff, some islands and countries I have never heard of, etc. <br /> \n",
    "After doing that, we save the new csv file again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_Countries_drop_Unnecessary(df, name): \n",
    "    print(\"Before {} shape: {}\".format(name, df.shape))\n",
    "    # Input is only the dataframe with the country names in the column 'Entity'\n",
    "    right_names = []\n",
    "    for data in df['Entity']:\n",
    "        ## RENAMING COUNTRIES FOR DATA CONSISTENCY\n",
    "        if 'Hong Kong' in data:\n",
    "            data = 'Hong Kong'\n",
    "        if 'Taiwan' in data: \n",
    "            data = 'Taiwan'\n",
    "        if 'Macao' in data: \n",
    "            data = 'Macao'\n",
    "        if 'Ethiopia' in data: \n",
    "            data = 'Ethiopia'\n",
    "        if 'Sudan' in data: \n",
    "            data = 'Sudan'        \n",
    "        if 'Czechia' in data: \n",
    "            data = 'Czech Republic'\n",
    "        if 'Syria' in data: \n",
    "            data = 'Syria'\n",
    "        if 'Russ' in data: \n",
    "            data = 'Russia'\n",
    "        if \"Ivoire\" in data:\n",
    "            data = \"Cote d'Ivoire\"\n",
    "\n",
    "        # America \n",
    "        if 'US' in data: \n",
    "            data = 'United States'\n",
    "        if 'USA' in data: \n",
    "            data = 'United States'\n",
    "        if 'U.S.A.' in data: \n",
    "            data = 'United States'\n",
    "        if 'U.S.A' in data: \n",
    "            data = 'United States'\n",
    "        if 'United States of' in data: # gets United States of America\n",
    "            data = 'United States'\n",
    "        if data == 'America': \n",
    "            data = 'United States'\n",
    "        right_names.append(data) \n",
    "        \n",
    "    ## Replace the names with the consistent names of them\n",
    "    right_names = pd.Series(right_names)\n",
    "    df['Entity'] = right_names\n",
    "\n",
    "    ## DELETE THE ENTRIES WHICH ARE NOT IN OUR MASTER COUNTRY LIST\n",
    "    countries = list(set(df[\"Entity\"]))\n",
    "    for country in countries: \n",
    "        if country not in interested_countries:\n",
    "            idx = list(df['Entity']).index(country)\n",
    "            endCountry = idx + list(df['Entity']).count(country)\n",
    "            ranges = np.arange( idx , endCountry )  \n",
    "            df.drop(df.index[ranges], inplace = True)\n",
    "    \n",
    "    ## SAVE THE FILE REDUCED AND CHANGED NAME AGAIN\n",
    "    print(\"After: {}\".format(df.shape))\n",
    "    df.to_csv(os.path.join(datapath, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the countries we want to have in our Masterlist and thus in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interested_countries = ['Sweden', 'Norway', 'Finland', 'Iceland', 'Germany', 'Netherlands', 'Belgium', 'Luxembourg',\n",
    "                        'England', 'Scotland', 'Wales', 'Ireland', 'United Kingdom', 'Switzerland', 'Austria', 'France'\n",
    "                        'Italy', 'Spain', 'Portugal', 'Morocco', 'Tunisia', 'Egypt', 'Liechtenstein', 'Cyprus', 'Vatican',\n",
    "                        'Kosovo', 'Serbia', 'Georgia', 'Greenland', 'Antigua and Barbuda', 'Hungary', 'Monaco', 'Israel',\n",
    "                        'Albania', 'Iraq', 'Iran', 'Syria', 'Turkey', 'Palestine', 'Montenegro', 'Latvia', 'Jordan',\n",
    "                        'Croatia', 'New Zealand', 'Eritrea', 'Libya', 'Belarus', 'Slovenia', 'Greece', 'Lithuania',\n",
    "                        'Liberia', 'Slovakia', 'Estonia', 'Poland', 'Czech Republic', 'Armenia', 'Denmark', 'Bulgaria',\n",
    "                        \n",
    "                        'Russia', 'United States', 'Canada', 'Qatar', 'Kuwait', 'Mexico', 'South Africa', 'Fiji', 'Oman',\n",
    "                        'Japan', 'United Arab Emirates', 'South Korea', 'Macao', 'Hong Kong', 'China', 'Thailand', 'Belize',\n",
    "                        'Taiwan', 'Vietnam', 'Malaysia', 'Indonesia', 'India', 'Philippines', 'Australia', 'Laos', 'Bhutan',\n",
    "                        \n",
    "                        'Kyrgyzstan', 'Kazakhstan', 'Uzbekistan', 'Turkmenistan', 'Tajikistan', 'Pakistan', 'Afghanistan',\n",
    "                        'Argentina', 'Brazil', 'Chile', 'Venezuela', 'Peru', 'Colombia', 'Guyana', 'Mauritius', 'Barbados', \n",
    "                        'Cuba', 'Panama', 'Bahamas', 'Puerto Rico', 'Costa Rica', 'Solomon Islands',  'Marshall Islands',\n",
    "                        'Ecuador', 'Benin', 'Seychelles', 'Bolivia', 'Madagascar',  'Mauritania', 'Bosnia and Herzegovina', \n",
    "                        'Jamaica', 'Lebanon', 'Senegal', 'Malta', 'French Polynesia', 'Bahrain', 'Burundi', 'Swaziland',\n",
    "                        'Tanzania', 'Central African Republic', 'Malawi', 'Djibouti', 'Mozambique', 'Macedonia', 'Sierra Leone',\n",
    "                        'Democratic Republic of Congo', 'Namibia', 'Algeria', 'Trinidad and Tobago', \"Cote d'Ivoire\",\n",
    "                         \n",
    "                        'Samoa', 'Bermuda', 'Aruba', 'Myanmar', 'Cape Verde', 'Uganda', 'Togo', 'Guinea', \n",
    "                        'San Marino', 'Ukraine', 'North Korea', 'Papua New Guinea', 'Haiti', 'Ghana', 'Sudan',\n",
    "                        'Faeroe Islands', 'Cambodia', 'Somalia',  'Kiribati', 'Tonga', 'Mongolia', 'Rwanda', 'Bangladesh',\n",
    "                        'Suriname', 'Nauru', 'Zambia', 'Azerbaijan',  'Sri Lanka', 'Nigeria', 'Kenya', 'Comoros', 'Andorra', \n",
    "                        'Tuvalu', 'Zimbabwe', 'Yemen', 'Cameroon', 'El Salvador', 'Angola', 'Curacao', 'Nicaragua',\n",
    "                        'Saudi Arabia', 'Lesotho', 'Moldova', 'Gabon', 'Grenada', 'Mali', 'Romania', 'Guatemala', 'Dominican Republic', \n",
    "                        'Honduras', 'Congo',  'Burkina Faso',  'Saint Lucia', 'Cayman Islands', 'Botswana', 'Ethiopia', \n",
    "                        'Chad', 'Uruguay', 'Maldives', 'Gibraltar', 'Paraguay', 'Niger', 'Nepal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lenny\\\\Documents\\\\Studium_Robotics (M.Sc.)\\\\03_Semester 3 - Oslo ERASMUS\\\\01_Applied Data Analysis and Machine Learning\\\\Project 3\\\\data\\\\Health'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path where we have our data stored and want to have it stored as well.\n",
    "datapath = os.path.join(os.path.join(os.getcwd(), 'data'), 'Health')\n",
    "datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call each single file in our data directory and process each one according to the rules we set previously (Renaming and Deleting entries). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problems with this guy: 00_insufficient-activity-adults.xlsx\n",
      "problems with this guy: 00_mean-systolic-blood-pressure.xlsx\n",
      "problems with this guy: 00_mean-total-cholesterol.xlsx\n",
      "Before agricultural-area-per-capita.csv shape: (8993, 4)\n",
      "After: (7753, 4)\n",
      "Before alcohol-attributable-fraction-of-mortality.csv shape: (190, 4)\n",
      "After: (173, 4)\n",
      "Before annual-healthcare-expenditure-per-capita.csv shape: (4675, 4)\n",
      "After: (3460, 4)\n",
      "Before average-height-of-men-for-selected-countries.csv shape: (1250, 4)\n",
      "After: (1203, 4)\n",
      "Before beer-consumption-per-person.csv shape: (8952, 4)\n",
      "After: (8268, 4)\n",
      "Before cancer-death-rates.csv shape: (6468, 4)\n",
      "After: (5068, 4)\n",
      "Before cardiovascular-disease-death-rates.csv shape: (6468, 4)\n",
      "After: (5068, 4)\n",
      "Before child-mortality.csv shape: (13512, 4)\n",
      "After: (12383, 4)\n",
      "Before co-emissions-per-capita.csv shape: (42844, 4)\n",
      "After: (39453, 4)\n",
      "Before consumption-per-smoker-per-day.csv shape: (6204, 4)\n",
      "After: (5742, 4)\n",
      "Before dementia-death-rates.csv shape: (6468, 4)\n",
      "After: (5068, 4)\n",
      "Before diarrheal-disease-death-rates.csv shape: (6468, 4)\n",
      "After: (5068, 4)\n",
      "Before fish-and-seafood-consumption-per-capita.csv shape: (10393, 4)\n",
      "After: (7714, 4)\n",
      "Before fruit-consumption-per-capita.csv shape: (10393, 4)\n",
      "After: (7714, 4)\n",
      "Before global-prevalence-of-zinc-deficiency.csv shape: (752, 4)\n",
      "After: (700, 4)\n",
      "Before happiness-cantril-ladder.csv shape: (1704, 4)\n",
      "After: (1658, 4)\n",
      "Before human-development-index.csv shape: (5001, 4)\n",
      "After: (4651, 4)\n",
      "Before intentional-homicides-per-100000-people.csv shape: (3011, 4)\n",
      "After: (2634, 4)\n",
      "Before international-tourism-number-of-arrivals.csv shape: (5209, 4)\n",
      "After: (3762, 4)\n",
      "Before life-expectancy.csv shape: (19028, 4)\n",
      "After: (15216, 4)\n",
      "Before maddison-data-gdp-per-capita-in-2011us.csv shape: (18202, 4)\n",
      "After: (15874, 4)\n",
      "Before maternal-mortality.csv shape: (7086, 4)\n",
      "After: (5578, 4)\n",
      "Before mean-years-of-schooling-1.csv shape: (7763, 4)\n",
      "After: (7327, 4)\n",
      "Before meat-production-tonnes.csv shape: (12652, 4)\n",
      "After: (8895, 4)\n",
      "Before meat-supply-per-person.csv shape: (10393, 4)\n",
      "After: (7714, 4)\n",
      "Before median-age.csv shape: (7471, 4)\n",
      "After: (5549, 4)\n",
      "Before merchandise-exports-gdp-cepii.csv shape: (13808, 4)\n",
      "After: (12031, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenny\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before military-expenditure-as-share-of-gdp.csv shape: (9172, 4)\n",
      "After: (6667, 4)\n",
      "Before milk-production-tonnes.csv shape: (11789, 4)\n",
      "After: (8572, 4)\n",
      "Before minutes-spent-on-leisure-men.csv shape: (31, 4)\n",
      "After: (28, 4)\n",
      "Before minutes-spent-on-leisure-women.csv shape: (31, 4)\n",
      "After: (28, 4)\n",
      "Before number-of-nurses.csv shape: (650, 4)\n",
      "After: (582, 4)\n",
      "Before per-capita-egg-consumption-kilograms-per-year.csv shape: (10393, 4)\n",
      "After: (7714, 4)\n",
      "Before per-capita-milk-consumption.csv shape: (10393, 4)\n",
      "After: (7714, 4)\n",
      "Before pisa-test-score-mean-performance-on-the-mathematics-scale.csv shape: (341, 4)\n",
      "After: (326, 4)\n",
      "Before pisa-test-score-mean-performance-on-the-science-scale.csv shape: (344, 4)\n",
      "After: (329, 4)\n",
      "Before population-density.csv shape: (14600, 4)\n",
      "After: (10623, 4)\n",
      "Before prevalence-of-anemia-in-pregnant-women.csv shape: (6093, 4)\n",
      "After: (4725, 4)\n",
      "Before prevalence-of-vitamin-a-deficiency-in-pregnant-women.csv shape: (162, 4)\n",
      "After: (142, 4)\n",
      "Before respiratory-disease-death-rate.csv shape: (6468, 4)\n",
      "After: (5068, 4)\n",
      "Before share-of-adults-defined-as-obese.csv shape: (8316, 4)\n",
      "After: (7308, 4)\n",
      "Before share-of-adults-who-are-overweight.csv shape: (8316, 4)\n",
      "After: (7308, 4)\n",
      "Before share-of-adults-who-smoke.csv shape: (1680, 4)\n",
      "After: (1242, 4)\n",
      "Before share-of-deaths-obesity.csv shape: (6412, 4)\n",
      "After: (4984, 4)\n",
      "Before share-of-population-urban.csv shape: (15072, 4)\n",
      "After: (10954, 4)\n",
      "Before share-of-population-who-never-drink-alcohol.csv shape: (189, 4)\n",
      "After: (172, 4)\n",
      "Before share-of-the-population-living-in-extreme-poverty.csv shape: (1602, 4)\n",
      "After: (1360, 4)\n",
      "Before share-of-the-population-with-access-to-electricity.csv shape: (6958, 4)\n",
      "After: (5083, 4)\n",
      "Before share-of-the-population-with-access-to-improved-drinking-water.csv shape: (6248, 4)\n",
      "After: (4570, 4)\n",
      "Before share-who-have-not-drank-alcohol-in-last-year.csv shape: (189, 4)\n",
      "After: (172, 4)\n",
      "Before share-with-mental-and-substance-disorders.csv shape: (6468, 4)\n",
      "After: (5068, 4)\n",
      "Before spirits-consumption-per-person.csv shape: (8953, 4)\n",
      "After: (8269, 4)\n",
      "Before stroke-death-rates.csv shape: (6468, 4)\n",
      "After: (5068, 4)\n",
      "Before suicide-death-rates.csv shape: (6468, 4)\n",
      "After: (5068, 4)\n",
      "Before taxes-on-incomes-of-individuals-and-corporations-gdp.csv shape: (4871, 4)\n",
      "After: (4472, 4)\n",
      "Before total-alcohol-consumption-per-capita-litres-of-pure-alcohol.csv shape: (233, 4)\n",
      "After: (173, 4)\n",
      "Before total-government-expenditure-on-education-gdp.csv shape: (4361, 4)\n",
      "After: (3346, 4)\n",
      "Before total-healthcare-expenditure-as-share-of-national-gdp-by-country.csv shape: (4670, 4)\n",
      "After: (3460, 4)\n",
      "Before total-tax-revenues-gdp.csv shape: (5318, 4)\n",
      "After: (4834, 4)\n",
      "Before vegetable-consumption-per-capita.csv shape: (10393, 4)\n",
      "After: (7714, 4)\n",
      "Before wine-consumption-per-person.csv shape: (8953, 4)\n",
      "After: (8269, 4)\n"
     ]
    }
   ],
   "source": [
    "dataFileNames = [f for f in os.listdir(datapath) if os.path.isfile(os.path.join(datapath, f))]\n",
    "type4Cols = []\n",
    "type7Cols = []\n",
    "manualLists = []\n",
    "\n",
    "# the datasets mostly have the same size of 4 columns and same setup so let's get those first\n",
    "\n",
    "for file in dataFileNames: \n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(datapath, str(file) ) , encoding='latin-1')\n",
    "    except: \n",
    "        print(\"problems with this guy: {}\".format(file))\n",
    "        manualLists.append(file)\n",
    "    if df.shape[1] == 4: # one type of files (4 columns) \n",
    "        type4Cols.append(file) \n",
    "        rename_Countries_drop_Unnecessary(df, str(file))\n",
    "        \n",
    "    elif df.shape[1] == 7: \n",
    "        type7Cols.append(file) \n",
    "    else: # manual shit  to do then \n",
    "        manualLists.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the final dataframe which we are going to use in the Analysis part. <br /> \n",
    "Notice that I set it up with 5mio rows, however this is just to ensure that all the data will be safely stored in it. I will delete the empty rows after the dataset is created. <br /> \n",
    "So, it's just a placeholder until now and serves the purpose of not running into index errors/ too small row size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000000, 196)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe where we want to paste everything inside\n",
    "# 5.000.000 rows to not run into some problems while adding rows - delete later the other ones\n",
    "final_df = pd.DataFrame(data = np.zeros( (5000000, len(interested_countries)) ), \n",
    "                        index = np.arange(5000000),\n",
    "                        columns = [ country for country in interested_countries])\n",
    "# save indices as strings to get meaningful names\n",
    "final_df.index = final_df.index.map(str)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a Testbench for getting the values I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to get values of the specific entries and Co\n",
    "columns = list(df.columns)\n",
    "b = df[df['Entity'] == 'France']\n",
    "c = b[b['Year'] == 1999]#[columns[-1]]\n",
    "d = b[b['Year'] == 1999][columns[-1]].sum()\n",
    "print(d)\n",
    "c\n",
    "#df.groupby([\"Entity\", 'Year']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Magic happens down here. <br /> \n",
    "We loop through every preprocessed list, <br /> \n",
    "In each list we loop through every country and further <br /> \n",
    "we also iterate over each year in that country. <br /> \n",
    "There I use the Year and the name of the file/list to create an index name. In this index name we paste the respective country and its value in it. <br /> \n",
    "We do this for all the preprocessed lists, which takes a shit ton of time. <br /> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 list out of 61, Index: 0, Name: agricultural-area-per-capita.csv\n",
      "\t\tAgriculutral are per capita [h/person] in 1980\n",
      "\t\tAgriculutral are per capita [h/person] in 2000\n",
      "\tWorking on country: 0 out of 161\n",
      "\tWorking on country: 60 out of 161\n",
      "\tWorking on country: 120 out of 161\n",
      "1 list out of 61, Index: 53, Name: alcohol-attributable-fraction-of-mortality.csv\n",
      "\tWorking on country: 0 out of 172\n",
      "\tWorking on country: 60 out of 172\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# paste the values into the final_df from each single list\n",
    "nextListIndex = 0\n",
    "\n",
    "try: \n",
    "    for lists in type4Cols:\n",
    "        \n",
    "        ## Read the file and get the all countries along with their reported years\n",
    "        print(\"{} list out of {}, Index: {}, Name: {}\".format(type4Cols.index(lists), len(type4Cols), nextListIndex, lists))\n",
    "        df = pd.read_csv(os.path.join(datapath, str(lists) ) , encoding='latin-1')\n",
    "        \n",
    "        # get the col names, unique countries and unique years\n",
    "        columns = list(df.columns)\n",
    "        countries = list(set(df[\"Entity\"]))\n",
    "        years = list(set(df['Year']))\n",
    "        \n",
    "        # get a list of all the index/row names\n",
    "        indexNamesArr = final_df.index.values\n",
    "\n",
    "        ## groupby countries and then years accordingly\n",
    "        #df.groupby([\"Entity\", 'Year'])\n",
    "\n",
    "        firstListRun = False # flag for renaming the indices\n",
    "\n",
    "        # loop thru every country in the list\n",
    "        for country in countries:\n",
    "            \n",
    "            ## check if country is in our masterlist\n",
    "            if country not in interested_countries: \n",
    "                # skip this item\n",
    "                print(\"\\tCountry: {} not in list - but we skip it.\".format(country))\n",
    "                continue\n",
    "            \n",
    "            # take a dataframe for one country at a time\n",
    "            country_df = df[df['Entity'] == country]\n",
    "\n",
    "            # loop thru every year within that country - assuming the years are in the same order for every country\n",
    "            for year in years:\n",
    "                \n",
    "                # rename the indices only if it is the very first run for the country\n",
    "                if not firstListRun:\n",
    "                    indexName = str(columns[-1]) + ' in ' + str(year)\n",
    "                    indexNamesArr[nextListIndex] = indexName\n",
    "                    nextListIndex += 1\n",
    "                    if nextListIndex % 20 == 0: \n",
    "                        print(\"\\t\\t\" + str(indexName))\n",
    "\n",
    "                ## get the proper value and fill empty ones, if not available, fill it with 0.000\n",
    "                # note: .sum() is only having one element anyway, just done to get the value as a float not an array\n",
    "                value = country_df[country_df[\"Year\"] == year][columns[-1]].sum() if not country_df[country_df[\"Year\"] == year][columns[-1]].empty else 0.000\n",
    "                # get the name of the row\n",
    "                idxName = str(columns[-1]) + ' in ' + str(year)\n",
    "                \n",
    "                #print(\"Country: {} found in the dataset at spot: {}\".format(country, interested_countries.index(country)))\n",
    "                \n",
    "                # assign the value in the merged df with the value \n",
    "                final_df.iat[list(final_df.index.values).index(idxName), interested_countries.index(country)] = value # .iat[row, col]\n",
    "\n",
    "            ## get the proper index for the next list to begin with   \n",
    "            firstListRun = True\n",
    "            # print progress\n",
    "            if countries.index(country) % 60 == 0:\n",
    "                print(\"\\tWorking on country: {} out of {}\".format(countries.index(country), len(countries)))\n",
    "            \n",
    "except Exception as e:\n",
    "    print(\"Next List Index in line: {} of {}, Matrix Size: {}, list: {}, country: {}\".format(i, nextListIndex, final_df.shape[0], lists, country))\n",
    "    print(e)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete all the values which are 0\n",
    "finale = final_df.copy()\n",
    "finale.dropna(how = 'all', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally save our sweet dataframe! **HURRRRRAAAAAAAAYY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(os.path.join(datapath, \"Merged UN Data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW HERE IS JUST THE PLAYGROUND TO TRY SOME STUFF OUT -> The dataset should be done in the top part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Entity')['Wine Consumption'].sum().sort_values().tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Entity'] == 'Germany']['Wine Consumption'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
