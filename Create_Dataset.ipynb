{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET CREATION\n",
    "\n",
    "Unfortunately, the dataset I will work with does not come as one already done dataset - as it is mostly usual in Data Science projects. <br /> \n",
    "To get the sheer experience of how a normal Data Science job looks like I also wanted to dive into this issue. By experience I can tell that this takes a shit ton of time - like almost 80% - of preparing the data. <br /> \n",
    "Since the data usually shares the same countries and lists mostly the same years of the recording I used this as a primary key where I connect the datapoints with each other. <br /> \n",
    "However, the  countries are listed in rows along with the year of the recording - I want to have a final dataset that looks like follows: <br /> \n",
    "\n",
    "|Country | Afghanistan | Albania | ... | Zimbabwe | \n",
    "| ----- | ----------  | ------ | ----- | ------- | \n",
    "|Alcohol consumption [l] | 0.2 | 2.4 | ... | 0.01 |\n",
    "|Human Develpment Index (HDI) | 0.1 | 0.15 | ... | 0.1 | \n",
    "|... | ... | ... | ... | ... |\n",
    "|Healthcare Expenditure [$] | 13.322 | 15.211 | ... | 1.039 |\n",
    "\n",
    "Thus, I have to transpose each of the countries and record each of the years as seperate entry in the dataset. <br /> \n",
    "\n",
    "All the data is [publicly available](https://ourworldindata.org), and this source is trusted by many notorious companies such as Vox, The Ney York times and even the top universities of this world like MIT, Oxford, Stanford. <br /> \n",
    "Hence, I assume that this data is rather based on actual recording from the respective country. <br /> \n",
    "Even the United Nation published their records in this page and I bet that these folks do some amazing work, which we can trust. <br />\n",
    "\n",
    "I downloaded 74 lists with different indicator variables ranging from the Human Developemnt Index (HDI) over the life expectancy until poultry consumption per capita for several years. Hence there is a lot of data in it and I am just sratching the surface of these datasets of the UN, WHO and FAO. <br /> \n",
    "\n",
    "One more thing to mention with respect to the countries is that some of them were only listed together such as *Serbia and Montenegro*, *Belgium Luxembourg*, ... and thus sometimes there is no single value for these countries available due to their combined listing. I decided not to give the credits only one specific country due to the unproportionality in their population and possibly cultural changes. <br /> \n",
    "\n",
    "But now let's not waste too much with the explaination part and go straight into how I merged the datafiles to one huge on. <br /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the preprocessing necessities with renaming the columns and dropping the ones we are not interested in, i.e. continents aggregated stuff, some islands and countries I have never heard of, etc. <br /> \n",
    "After doing that, we save the new csv file again.  <br /> \n",
    "Moreover, I also delete all the entries of 1979 and before to not have too much history data, which speeds up the computation by a looooot at least 1 day of computation saved due to that! <br /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_Countries_drop_Unnecessary(df, name): \n",
    "    print(\"Before {} shape: {}\".format(name, df.shape))\n",
    "    # Input is only the dataframe with the country names in the column 'Entity'\n",
    "    right_names = []\n",
    "    for data in df['Entity']:\n",
    "        ## RENAMING COUNTRIES FOR DATA CONSISTENCY\n",
    "        if 'Hong Kong' in data:\n",
    "            data = 'Hong Kong'\n",
    "        if 'Taiwan' in data: \n",
    "            data = 'Taiwan'\n",
    "        if 'Macao' in data: \n",
    "            data = 'Macao'\n",
    "        if 'Ethiopia' in data: \n",
    "            data = 'Ethiopia'\n",
    "        if 'Sudan' in data: \n",
    "            data = 'Sudan'        \n",
    "        if 'Czechia' in data: \n",
    "            data = 'Czech Republic'\n",
    "        if 'Syria' in data: \n",
    "            data = 'Syria'\n",
    "        if 'Russia' in data: \n",
    "            data = 'Russia'\n",
    "        if \"Ivoire\" in data:\n",
    "            data = \"Cote d'Ivoire\"\n",
    "\n",
    "        # America \n",
    "        if 'US' in data: \n",
    "            data = 'United States'\n",
    "        if 'USA' in data: \n",
    "            data = 'United States'\n",
    "        if 'U.S.A.' in data: \n",
    "            data = 'United States'\n",
    "        if 'U.S.A' in data: \n",
    "            data = 'United States'\n",
    "        if 'United States of' in data: # gets United States of America\n",
    "            data = 'United States'\n",
    "        if data == 'America': \n",
    "            data = 'United States'\n",
    "        right_names.append(data) \n",
    "        \n",
    "    ## Replace the names with the consistent names of them\n",
    "    right_names = pd.Series(right_names)\n",
    "    df['Entity'] = right_names\n",
    "\n",
    "    ## DELETE THE ENTRIES WHICH ARE NOT IN OUR MASTER COUNTRY LIST\n",
    "    countries = list(set(df[\"Entity\"]))\n",
    "    for country in countries: \n",
    "        if country not in interested_countries:\n",
    "            idx = list(df['Entity']).index(country)\n",
    "            endCountry = idx + list(df['Entity']).count(country)\n",
    "            ranges = np.arange( idx , endCountry )  \n",
    "            df.drop(df.index[ranges], inplace = True)\n",
    "            \n",
    "    ## DELETE ENTRIES BEFORE 1980\n",
    "    df = df[df[\"Year\"] > 1979]\n",
    "    \n",
    "    ## SAVE THE FILE REDUCED AND CHANGED NAME AGAIN\n",
    "    print(\"After: {}\".format(df.shape))\n",
    "    df.to_csv(os.path.join(datapath, name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the countries we want to have in our Masterlist and thus in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interested_countries = ['Sweden', 'Norway', 'Finland', 'Iceland', 'Germany', 'Netherlands', 'Belgium', 'Luxembourg',\n",
    "                        'England', 'Scotland', 'Wales', 'Ireland', 'United Kingdom', 'Switzerland', 'Austria', 'France',\n",
    "                        'Italy', 'Spain', 'Portugal', 'Morocco', 'Tunisia', 'Egypt', 'Liechtenstein', 'Cyprus', 'Vatican',\n",
    "                        'Kosovo', 'Serbia', 'Georgia', 'Greenland', 'Antigua and Barbuda', 'Hungary', 'Monaco', 'Israel',\n",
    "                        'Albania', 'Iraq', 'Iran', 'Syria', 'Turkey', 'Palestine', 'Montenegro', 'Latvia', 'Jordan',\n",
    "                        'Croatia', 'New Zealand', 'Eritrea', 'Libya', 'Belarus', 'Slovenia', 'Greece', 'Lithuania',\n",
    "                        'Liberia', 'Slovakia', 'Estonia', 'Poland', 'Czech Republic', 'Armenia', 'Denmark', 'Bulgaria',\n",
    "                        \n",
    "                        'Russia', 'United States', 'Canada', 'Qatar', 'Kuwait', 'Mexico', 'South Africa', 'Fiji', 'Oman',\n",
    "                        'Japan', 'United Arab Emirates', 'South Korea', 'Macao', 'Hong Kong', 'China', 'Thailand', 'Belize',\n",
    "                        'Taiwan', 'Vietnam', 'Malaysia', 'Indonesia', 'India', 'Philippines', 'Australia', 'Laos', 'Bhutan',\n",
    "                        \n",
    "                        'Kyrgyzstan', 'Kazakhstan', 'Uzbekistan', 'Turkmenistan', 'Tajikistan', 'Pakistan', 'Afghanistan',\n",
    "                        'Argentina', 'Brazil', 'Chile', 'Venezuela', 'Peru', 'Colombia', 'Guyana', 'Mauritius', 'Barbados', \n",
    "                        'Cuba', 'Panama', 'Bahamas', 'Puerto Rico', 'Costa Rica', 'Solomon Islands',  'Marshall Islands',\n",
    "                        'Ecuador', 'Benin', 'Seychelles', 'Bolivia', 'Madagascar',  'Mauritania', 'Bosnia and Herzegovina', \n",
    "                        'Jamaica', 'Lebanon', 'Senegal', 'Malta', 'French Polynesia', 'Bahrain', 'Burundi', 'Swaziland',\n",
    "                        'Tanzania', 'Central African Republic', 'Malawi', 'Djibouti', 'Mozambique', 'Macedonia', 'Sierra Leone',\n",
    "                        'Democratic Republic of Congo', 'Namibia', 'Algeria', 'Trinidad and Tobago', \"Cote d'Ivoire\",\n",
    "                         \n",
    "                        'Samoa', 'Bermuda', 'Aruba', 'Myanmar', 'Cape Verde', 'Uganda', 'Togo', 'Guinea', \n",
    "                        'San Marino', 'Ukraine', 'North Korea', 'Papua New Guinea', 'Haiti', 'Ghana', 'Sudan',\n",
    "                        'Faeroe Islands', 'Cambodia', 'Somalia',  'Kiribati', 'Tonga', 'Mongolia', 'Rwanda', 'Bangladesh',\n",
    "                        'Suriname', 'Nauru', 'Zambia', 'Azerbaijan',  'Sri Lanka', 'Nigeria', 'Kenya', 'Comoros', 'Andorra', \n",
    "                        'Tuvalu', 'Zimbabwe', 'Yemen', 'Cameroon', 'El Salvador', 'Angola', 'Curacao', 'Nicaragua',\n",
    "                        'Saudi Arabia', 'Lesotho', 'Moldova', 'Gabon', 'Grenada', 'Mali', 'Romania', 'Guatemala', 'Dominican Republic', \n",
    "                        'Honduras', 'Congo',  'Burkina Faso',  'Saint Lucia', 'Cayman Islands', 'Botswana', 'Ethiopia', \n",
    "                        'Chad', 'Uruguay', 'Maldives', 'Gibraltar', 'Paraguay', 'Niger', 'Nepal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lenny\\\\Documents\\\\Studium_Robotics (M.Sc.)\\\\03_Semester 3 - Oslo ERASMUS\\\\01_Applied Data Analysis and Machine Learning\\\\Project 3\\\\data\\\\Health'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path where we have our data stored and want to have it stored as well.\n",
    "datapath = os.path.join(os.path.join(os.getcwd(), 'data'), 'Health')\n",
    "datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call each single file in our data directory and process each one according to the rules we set previously (Renaming and Deleting entries). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before agricultural-area-per-capita.csv shape: (5150, 4)\n",
      "After: (5150, 4)\n",
      "Before alcohol-attributable-fraction-of-mortality.csv shape: (173, 4)\n",
      "After: (173, 4)\n",
      "Before annual-healthcare-expenditure-per-capita.csv shape: (3460, 4)\n",
      "After: (3460, 4)\n",
      "Before average-height-of-men-for-selected-countries.csv shape: (91, 4)\n",
      "After: (91, 4)\n",
      "Before beef-consumption-per-dude.csv shape: (5198, 4)\n",
      "After: (5198, 4)\n",
      "Before beer-consumption-per-person.csv shape: (5556, 4)\n",
      "After: (5556, 4)\n",
      "Before cancer-death-rates.csv shape: (5068, 4)\n",
      "After: (5068, 4)\n",
      "Before cardiovascular-disease-death-rates.csv shape: (5068, 4)\n",
      "After: (5068, 4)\n",
      "Before child-mortality.csv shape: (6434, 4)\n",
      "After: (6434, 4)\n",
      "Before co-emissions-per-capita.csv shape: (6878, 4)\n",
      "After: (6878, 4)\n",
      "Before consumption-per-smoker-per-day.csv shape: (5742, 4)\n",
      "After: (5742, 4)\n",
      "Before dementia-death-rates.csv shape: (5068, 4)\n",
      "After: (5068, 4)\n",
      "Before diarrheal-disease-death-rates.csv shape: (5068, 4)\n",
      "After: (5068, 4)\n",
      "Before fish-and-seafood-consumption-per-capita.csv shape: (5130, 4)\n",
      "After: (5130, 4)\n",
      "Before fruit-consumption-per-capita.csv shape: (5130, 4)\n",
      "After: (5130, 4)\n",
      "Before global-meat-production-by-livestock-type.csv shape: (6022, 4)\n",
      "After: (6022, 4)\n",
      "Before global-prevalence-of-zinc-deficiency.csv shape: (700, 4)\n",
      "After: (700, 4)\n",
      "Before goat-mutton-consumption-per-capita.csv shape: (5198, 4)\n",
      "After: (5198, 4)\n",
      "Before happiness-cantril-ladder.csv shape: (1658, 4)\n",
      "After: (1658, 4)\n",
      "Before human-development-index.csv shape: (4651, 4)\n",
      "After: (4651, 4)\n",
      "Before insufficient-activity-adults.csv shape: (165, 4)\n",
      "After: (165, 4)\n",
      "Before intentional-homicides-per-100000-people.csv shape: (2634, 4)\n",
      "After: (2634, 4)\n",
      "Before international-tourism-number-of-arrivals.csv shape: (3762, 4)\n",
      "After: (3762, 4)\n",
      "Before life-expectancy.csv shape: (7680, 4)\n",
      "After: (7680, 4)\n",
      "Before maddison-data-gdp-per-capita-in-2011us.csv shape: (5862, 4)\n",
      "After: (5862, 4)\n",
      "Before maternal-mortality.csv shape: (4446, 4)\n",
      "After: (4446, 4)\n",
      "Before mean-systolic-blood-pressure-female.csv shape: (5952, 4)\n",
      "After: (5952, 4)\n",
      "Before mean-systolic-blood-pressure-male.csv shape: (5952, 4)\n",
      "After: (5952, 4)\n",
      "Before mean-total-cholesterol-female.csv shape: (4896, 4)\n",
      "After: (4896, 4)\n",
      "Before mean-total-cholesterol-male.csv shape: (4896, 4)\n",
      "After: (4896, 4)\n",
      "Before mean-years-of-schooling-1.csv shape: (4775, 4)\n",
      "After: (4775, 4)\n",
      "Before meat-production-tonnes.csv shape: (5955, 4)\n",
      "After: (5955, 4)\n",
      "Before meat-supply-per-person.csv shape: (5130, 4)\n",
      "After: (5130, 4)\n",
      "Before median-age.csv shape: (4475, 4)\n",
      "After: (4475, 4)\n",
      "Before merchandise-exports-gdp-cepii.csv shape: (5727, 4)\n",
      "After: (5727, 4)\n",
      "Before military-expenditure-as-share-of-gdp.csv shape: (4996, 4)\n",
      "After: (4996, 4)\n",
      "Before milk-production-tonnes.csv shape: (5741, 4)\n",
      "After: (5741, 4)\n",
      "Before minutes-spent-on-leisure-men.csv shape: (28, 4)\n",
      "After: (28, 4)\n",
      "Before minutes-spent-on-leisure-women.csv shape: (28, 4)\n",
      "After: (28, 4)\n",
      "Before number-of-nurses.csv shape: (582, 4)\n",
      "After: (582, 4)\n",
      "Before patents-granted.csv shape: (687, 4)\n",
      "After: (687, 4)\n",
      "Before per-capita-egg-consumption-kilograms-per-year.csv shape: (5130, 4)\n",
      "After: (5130, 4)\n",
      "Before per-capita-milk-consumption.csv shape: (5130, 4)\n",
      "After: (5130, 4)\n",
      "Before per-capita-poultry-consumptionper-year.csv shape: (5198, 4)\n",
      "After: (5198, 4)\n",
      "Before pig-consumption-per-dude.csv shape: (5198, 4)\n",
      "After: (5198, 4)\n",
      "Before pisa-test-score-mean-performance-on-the-mathematics-scale.csv shape: (326, 4)\n",
      "After: (326, 4)\n",
      "Before pisa-test-score-mean-performance-on-the-science-scale.csv shape: (329, 4)\n",
      "After: (329, 4)\n",
      "Before Population Growth, Fertility and Mortality Indicators.csv shape: (560, 4)\n",
      "After: (560, 4)\n",
      "Before population-density.csv shape: (7127, 4)\n",
      "After: (7127, 4)\n",
      "Before prevalence-of-anemia-in-pregnant-women.csv shape: (4725, 4)\n",
      "After: (4725, 4)\n",
      "Before prevalence-of-vitamin-a-deficiency-in-pregnant-women.csv shape: (142, 4)\n",
      "After: (142, 4)\n",
      "Before respiratory-disease-death-rate.csv shape: (5068, 4)\n",
      "After: (5068, 4)\n",
      "Before share-of-adults-defined-as-obese.csv shape: (6438, 4)\n",
      "After: (6438, 4)\n",
      "Before share-of-adults-who-are-overweight.csv shape: (6438, 4)\n",
      "After: (6438, 4)\n",
      "Before share-of-adults-who-smoke.csv shape: (1242, 4)\n",
      "After: (1242, 4)\n",
      "Before share-of-deaths-obesity.csv shape: (4984, 4)\n",
      "After: (4984, 4)\n",
      "Before share-of-population-urban.csv shape: (7194, 4)\n",
      "After: (7194, 4)\n",
      "Before share-of-population-who-never-drink-alcohol.csv shape: (172, 4)\n",
      "After: (172, 4)\n",
      "Before share-of-the-population-living-in-extreme-poverty.csv shape: (1356, 4)\n",
      "After: (1356, 4)\n",
      "Before share-of-the-population-with-access-to-electricity.csv shape: (5083, 4)\n",
      "After: (5083, 4)\n",
      "Before share-of-the-population-with-access-to-improved-drinking-water.csv shape: (4570, 4)\n",
      "After: (4570, 4)\n",
      "Before share-who-have-not-drank-alcohol-in-last-year.csv shape: (172, 4)\n",
      "After: (172, 4)\n",
      "Before share-with-mental-and-substance-disorders.csv shape: (5068, 4)\n",
      "After: (5068, 4)\n",
      "Before spirits-consumption-per-person.csv shape: (5557, 4)\n",
      "After: (5557, 4)\n",
      "Before stroke-death-rates.csv shape: (5068, 4)\n",
      "After: (5068, 4)\n",
      "Before suicide-death-rates.csv shape: (5068, 4)\n",
      "After: (5068, 4)\n",
      "Before taxes-on-incomes-of-individuals-and-corporations-gdp.csv shape: (4472, 4)\n",
      "After: (4472, 4)\n",
      "Before total-alcohol-consumption-per-capita-litres-of-pure-alcohol.csv shape: (173, 4)\n",
      "After: (173, 4)\n",
      "Before total-government-expenditure-on-education-gdp.csv shape: (2914, 4)\n",
      "After: (2914, 4)\n",
      "Before total-healthcare-expenditure-as-share-of-national-gdp-by-country.csv shape: (3460, 4)\n",
      "After: (3460, 4)\n",
      "Before total-meat-consumption-per-capita.csv shape: (5198, 4)\n",
      "After: (5198, 4)\n",
      "Before total-tax-revenues-gdp.csv shape: (4834, 4)\n",
      "After: (4834, 4)\n",
      "Before vegetable-consumption-per-capita.csv shape: (5130, 4)\n",
      "After: (5130, 4)\n",
      "Before wine-consumption-per-person.csv shape: (5557, 4)\n",
      "After: (5557, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Merged UN Data 1980+.csv', 'Merged UN Data.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFileNames = [f for f in os.listdir(datapath) if os.path.isfile(os.path.join(datapath, f))]\n",
    "type4Cols = []\n",
    "type7Cols = []\n",
    "manualLists = []\n",
    "\n",
    "# the datasets mostly have the same size of 4 columns and same setup so let's get those first\n",
    "\n",
    "for file in dataFileNames: \n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(datapath, str(file) ) , encoding='latin-1')\n",
    "    except: \n",
    "        print(\"problems with this guy: {}\".format(file))\n",
    "        manualLists.append(file)\n",
    "    if df.shape[1] == 5 or df.shape[1] == 4: # one type of files (4 columns)\n",
    "        type4Cols.append(file) \n",
    "        rename_Countries_drop_Unnecessary(df, str(file))\n",
    "    elif df.shape[1] == 7: \n",
    "        type7Cols.append(file) \n",
    "    else: # manual shit  to do then \n",
    "        manualLists.append(file)\n",
    "manualLists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the final dataframe which we are going to use in the Analysis part. <br /> \n",
    "Notice that I set it up with 5mio rows, however this is just to ensure that all the data will be safely stored in it. I will delete the empty rows after the dataset is created. <br /> \n",
    "So, it's just a placeholder until now and serves the purpose of not running into index errors/ too small row size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 197)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe where we want to paste everything inside\n",
    "# 5.000.000 rows to not run into some problems while adding rows - delete later the other ones\n",
    "final_df = pd.DataFrame(data = np.zeros( (5000, len(interested_countries)) ), \n",
    "                        index = np.arange(5000),\n",
    "                        columns = [ country for country in interested_countries])\n",
    "# save indices as strings to get meaningful names\n",
    "final_df.index = final_df.index.map(str)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a Testbench for getting the values I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing to get values of the specific entries and Co\n",
    "columns = list(df.columns)\n",
    "b = df[df['Entity'] == 'France']\n",
    "c = b[b['Year'] == 1999]#[columns[-1]]\n",
    "d = b[b['Year'] == 1999][columns[-1]].sum()\n",
    "print(d)\n",
    "c\n",
    "#df.groupby([\"Entity\", 'Year']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Magic happens down here. <br /> \n",
    "We loop through every preprocessed list, <br /> \n",
    "In each list we loop through every country and further <br /> \n",
    "we also iterate over each year in that country. <br /> \n",
    "There I use the Year and the name of the file/list to create an index name. In this index name we paste the respective country and its value in it. <br /> \n",
    "We do this for all the preprocessed lists, which takes a shit ton of time. <br /> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 list out of 74, Index: 0, Name: agricultural-area-per-capita.csv\n",
      "\t\tAgriculutral are per capita [h/person] in 1999\n",
      "\tWorking on country: 0 out of 161\n",
      "\tWorking on country: 60 out of 161\n",
      "\tWorking on country: 120 out of 161\n",
      "1 list out of 74, Index: 34, Name: alcohol-attributable-fraction-of-mortality.csv\n",
      "\tWorking on country: 0 out of 172\n",
      "\tWorking on country: 60 out of 172\n",
      "\tWorking on country: 120 out of 172\n",
      "2 list out of 74, Index: 35, Name: annual-healthcare-expenditure-per-capita.csv\n",
      "\t\tannual healthcare spending [$] in 1999\n",
      "\tWorking on country: 0 out of 174\n",
      "\tWorking on country: 60 out of 174\n",
      "\tWorking on country: 120 out of 174\n",
      "3 list out of 74, Index: 55, Name: average-height-of-men-for-selected-countries.csv\n",
      "\tWorking on country: 0 out of 91\n",
      "\tWorking on country: 60 out of 91\n",
      "4 list out of 74, Index: 56, Name: beef-consumption-per-dude.csv\n",
      "\t\tBeef and buffalo (kg) in 1983\n",
      "\t\tBeef and buffalo (kg) in 2003\n",
      "\tWorking on country: 0 out of 163\n",
      "\tWorking on country: 60 out of 163\n",
      "\tWorking on country: 120 out of 163\n",
      "5 list out of 74, Index: 90, Name: beer-consumption-per-person.csv\n",
      "\t\tBeer Consumption per capita [l] in 1989\n",
      "\t\tBeer Consumption per capita [l] in 2009\n",
      "\tWorking on country: 0 out of 173\n",
      "\tWorking on country: 60 out of 173\n",
      "\tWorking on country: 120 out of 173\n",
      "6 list out of 74, Index: 126, Name: cancer-death-rates.csv\n",
      "\t\tCancer Deaths [per 100,000] in 2003\n",
      "\tWorking on country: 0 out of 180\n",
      "\tWorking on country: 60 out of 180\n",
      "\tWorking on country: 120 out of 180\n",
      "7 list out of 74, Index: 154, Name: cardiovascular-disease-death-rates.csv\n",
      "\t\tCardiovascular diseases [deaths per 100,000] in 1995\n",
      "\t\tCardiovascular diseases [deaths per 100,000] in 2015\n",
      "\tWorking on country: 0 out of 180\n",
      "\tWorking on country: 60 out of 180\n",
      "\tWorking on country: 120 out of 180\n",
      "8 list out of 74, Index: 182, Name: child-mortality.csv\n",
      "\t\tUnder five mortality rate [% of children dying before 5] in 1997\n",
      "\tWorking on country: 0 out of 183\n",
      "\tWorking on country: 60 out of 183\n",
      "\tWorking on country: 120 out of 183\n",
      "\tWorking on country: 180 out of 183\n",
      "9 list out of 74, Index: 219, Name: co-emissions-per-capita.csv\n",
      "\t\tCO2 Emissions per capita [t] in 1980\n",
      "\t\tCO2 Emissions per capita [t] in 2000\n",
      "\tWorking on country: 0 out of 180\n",
      "\tWorking on country: 60 out of 180\n",
      "\tWorking on country: 120 out of 180\n",
      "10 list out of 74, Index: 257, Name: consumption-per-smoker-per-day.csv\n",
      "\t\tCigarettes per day in 1982\n",
      "\t\tCigarettes per day in 2002\n",
      "\tWorking on country: 0 out of 174\n",
      "\tWorking on country: 60 out of 174\n",
      "\tWorking on country: 120 out of 174\n",
      "11 list out of 74, Index: 290, Name: dementia-death-rates.csv\n",
      "\t\tAlzheimer disease and other dementias [deaths per 100,000] in 1999\n",
      "\tWorking on country: 0 out of 180\n",
      "\tWorking on country: 60 out of 180\n",
      "\tWorking on country: 120 out of 180\n",
      "12 list out of 74, Index: 318, Name: diarrheal-disease-death-rates.csv\n",
      "\t\tDiarrheal diseases [deaths per 100,000] in 1991\n",
      "\t\tDiarrheal diseases [deaths per 100,000] in 2011\n",
      "\tWorking on country: 0 out of 180\n",
      "\tWorking on country: 60 out of 180\n",
      "\tWorking on country: 120 out of 180\n",
      "13 list out of 74, Index: 346, Name: fish-and-seafood-consumption-per-capita.csv\n",
      "\t\tFish and Seafood consumption per capita [kg] in 1993\n",
      "\t\tFish and Seafood consumption per capita [kg] in 2013\n",
      "\tWorking on country: 0 out of 161\n",
      "\tWorking on country: 60 out of 161\n",
      "\tWorking on country: 120 out of 161\n",
      "14 list out of 74, Index: 380, Name: fruit-consumption-per-capita.csv\n",
      "\t\tfruit per capita [kg] in 1999\n",
      "\tWorking on country: 0 out of 161\n",
      "\tWorking on country: 60 out of 161\n",
      "\tWorking on country: 120 out of 161\n",
      "15 list out of 74, Index: 414, Name: global-meat-production-by-livestock-type.csv\n",
      "\t\tTotal [t] in 1985\n",
      "\t\tTotal [t] in 2005\n",
      "\tWorking on country: 0 out of 182\n",
      "\tWorking on country: 60 out of 182\n",
      "\tWorking on country: 120 out of 182\n",
      "\tWorking on country: 180 out of 182\n",
      "16 list out of 74, Index: 449, Name: global-prevalence-of-zinc-deficiency.csv\n",
      "\tWorking on country: 0 out of 175\n",
      "\tWorking on country: 60 out of 175\n",
      "\tWorking on country: 120 out of 175\n",
      "17 list out of 74, Index: 453, Name: goat-mutton-consumption-per-capita.csv\n",
      "\t\tMutton & goat (kg) in 1986\n",
      "\t\tMutton & goat (kg) in 2006\n",
      "\tWorking on country: 0 out of 163\n",
      "\tWorking on country: 60 out of 163\n",
      "\tWorking on country: 120 out of 163\n",
      "18 list out of 74, Index: 487, Name: happiness-cantril-ladder.csv\n",
      "\t\tWorld Happiness Report(Cantril Ladder [0=worst; 10=best]) in 2014\n",
      "\tWorking on country: 0 out of 158\n",
      "\tWorking on country: 60 out of 158\n",
      "\tWorking on country: 120 out of 158\n",
      "19 list out of 74, Index: 501, Name: human-development-index.csv\n",
      "\t\tHDI [0, ÃÂ",
      ", 1] in 2006\n",
      "\tWorking on country: 0 out of 173\n",
      "\tWorking on country: 60 out of 173\n",
      "\tWorking on country: 120 out of 173\n",
      "20 list out of 74, Index: 531, Name: insufficient-activity-adults.csv\n",
      "\tWorking on country: 0 out of 164\n",
      "\tWorking on country: 60 out of 164\n",
      "\tWorking on country: 120 out of 164\n",
      "21 list out of 74, Index: 532, Name: intentional-homicides-per-100000-people.csv\n",
      "\t\tHomicides [deaths per 100,000] in 2002\n",
      "\tWorking on country: 0 out of 188\n",
      "\tWorking on country: 60 out of 188\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# paste the values into the final_df from each single list\n",
    "nextListIndex = 0\n",
    "\n",
    "try: \n",
    "    for lists in type4Cols:\n",
    "        \n",
    "        ## Read the file and get the all countries along with their reported years\n",
    "        print(\"{} list out of {}, Index: {}, Name: {}\".format(type4Cols.index(lists), len(type4Cols), nextListIndex, lists))\n",
    "        df = pd.read_csv(os.path.join(datapath, str(lists) ) , encoding='latin-1')\n",
    "        \n",
    "        # get the col names, unique countries and unique years\n",
    "        columns = list(df.columns)\n",
    "        countries = list(set(df[\"Entity\"]))\n",
    "        years = list(set(df['Year']))\n",
    "        \n",
    "        # get a list of all the index/row names\n",
    "        indexNamesArr = final_df.index.values\n",
    "\n",
    "        ## groupby countries and then years accordingly\n",
    "        #df.groupby([\"Entity\", 'Year'])\n",
    "\n",
    "        firstListRun = False # flag for renaming the indices\n",
    "\n",
    "        # loop thru every country in the list\n",
    "        for country in countries:\n",
    "            \n",
    "            ## check if country is in our masterlist\n",
    "            if country not in interested_countries: \n",
    "                # skip this item\n",
    "                print(\"\\tCountry: {} not in list - but we skip it.\".format(country))\n",
    "                continue\n",
    "            \n",
    "            # take a dataframe for one country at a time\n",
    "            country_df = df[df['Entity'] == country]\n",
    "\n",
    "            # loop thru every year within that country - assuming the years are in the same order for every country\n",
    "            for year in years:\n",
    "                \n",
    "                # rename the indices only if it is the very first run for the country\n",
    "                if not firstListRun:\n",
    "                    indexName = str(columns[-1]) + ' in ' + str(year)\n",
    "                    indexNamesArr[nextListIndex] = indexName\n",
    "                    nextListIndex += 1\n",
    "                    if nextListIndex % 20 == 0: \n",
    "                        print(\"\\t\\t\" + str(indexName))\n",
    "\n",
    "                ## get the proper value and fill empty ones, if not available, fill it with 0.000\n",
    "                # note: .sum() is only having one element anyway, just done to get the value as a float not an array\n",
    "                value = country_df[country_df[\"Year\"] == year][columns[-1]].sum() if not country_df[country_df[\"Year\"] == year][columns[-1]].empty else 0.000\n",
    "                # get the name of the row\n",
    "                idxName = str(columns[-1]) + ' in ' + str(year)\n",
    "                \n",
    "                #print(\"Country: {} found in the dataset at spot: {}\".format(country, interested_countries.index(country)))\n",
    "                \n",
    "                # assign the value in the merged df with the value \n",
    "                final_df.iat[list(final_df.index.values).index(idxName), interested_countries.index(country)] = value # .iat[row, col]\n",
    "\n",
    "            ## get the proper index for the next list to begin with   \n",
    "            firstListRun = True\n",
    "            # print progress\n",
    "            if countries.index(country) % 60 == 0:\n",
    "                print(\"\\tWorking on country: {} out of {}\".format(countries.index(country), len(countries)))\n",
    "            \n",
    "except Exception as e:\n",
    "    print(\"Next List Index in line: {} of {}, Matrix Size: {}, list: {}, country: {}\".format(i, nextListIndex, final_df.shape[0], lists, country))\n",
    "    print(e)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastFilledItem = list(final_df.index).index(indexName) + 1\n",
    "final_df.drop(final_df.index[ np.arange(lastFilledItem, final_df.shape[0]) ], inplace=True)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally save our sweet dataframe! **HURRRRRAAAAAAAAYY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(os.path.join(datapath, \"Merged UN Data 1980+.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW HERE IS JUST THE PLAYGROUND TO TRY SOME STUFF OUT -> The dataset should be done in the top part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open my baby again \n",
    "df = pd.read_csv(os.path.join(datapath, \"Merged UN Data1980+.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[3550:3600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = 'maddison-data-gdp-per-capita-in-2011us.csv'\n",
    "df = pd.read_csv(os.path.join(datapath, gdp ) , encoding='latin-1')\n",
    "print(df.shape)\n",
    "result_df = df[df[\"Year\"] > 1979]\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VALIDATE BEER AND WINE CONSUMPTION\n",
    "vege = 'vegetable-consumption-per-capita.csv'\n",
    "wine = 'wine-consumption-per-person.csv'\n",
    "beer = 'beer-consumption-per-person.csv'\n",
    "\n",
    "\n",
    "test_df = pd.DataFrame(data = np.zeros( (500, len(interested_countries)) ), \n",
    "                        index = np.arange(500),\n",
    "                        columns = [ country for country in interested_countries])\n",
    "# save indices as strings to get meaningful names\n",
    "test_df.index = test_df.index.map(str)\n",
    "\n",
    "\n",
    "# paste the values into the final_df from each single list\n",
    "listies = [vege, wine, beer]\n",
    "nextListIndex = 0\n",
    "\n",
    "for lists in listies:\n",
    "\n",
    "    ## Read the file and get the all countries along with their reported years\n",
    "    df = pd.read_csv(os.path.join(datapath, str(lists) ) , encoding='latin-1')\n",
    "\n",
    "    # get the col names, unique countries and unique years\n",
    "    columns = list(df.columns)\n",
    "    countries = list(set(df[\"Entity\"]))\n",
    "    years = list(set(df['Year']))\n",
    "\n",
    "    # get a list of all the index/row names\n",
    "    indexNamesArr = test_df.index.values\n",
    "\n",
    "    ## groupby countries and then years accordingly\n",
    "    #df.groupby([\"Entity\", 'Year'])\n",
    "\n",
    "    firstListRun = False # flag for renaming the indices\n",
    "\n",
    "    # loop thru every country in the list\n",
    "    for country in countries:\n",
    "\n",
    "        ## check if country is in our masterlist\n",
    "        if country not in interested_countries: \n",
    "            # skip this item\n",
    "            print(\"\\tCountry: {} not in list - but we skip it.\".format(country))\n",
    "            continue\n",
    "\n",
    "        # take a dataframe for one country at a time\n",
    "        country_df = df[df['Entity'] == country]\n",
    "\n",
    "        # loop thru every year within that country - assuming the years are in the same order for every country\n",
    "        for year in years:\n",
    "\n",
    "            # rename the indices only if it is the very first run for the country\n",
    "            if not firstListRun:\n",
    "                indexName = str(columns[-1]) + ' in ' + str(year)\n",
    "                indexNamesArr[nextListIndex] = indexName\n",
    "                nextListIndex += 1\n",
    "                if nextListIndex % 20 == 0: \n",
    "                    print(\"\\t\\t\" + str(indexName))\n",
    "\n",
    "            ## get the proper value and fill empty ones, if not available, fill it with 0.000\n",
    "            # note: .sum() is only having one element anyway, just done to get the value as a float not an array\n",
    "            value = country_df[country_df[\"Year\"] == year][columns[-1]].sum() if not country_df[country_df[\"Year\"] == year][columns[-1]].empty else 0.000\n",
    "            # get the name of the row\n",
    "            idxName = str(columns[-1]) + ' in ' + str(year)\n",
    "\n",
    "            #print(\"Country: {} found in the dataset at spot: {}\".format(country, interested_countries.index(country)))\n",
    "\n",
    "            # assign the value in the merged df with the value \n",
    "            test_df.iat[list(test_df.index.values).index(idxName), interested_countries.index(country)] = value # .iat[row, col]\n",
    "\n",
    "        ## get the proper index for the next list to begin with   \n",
    "        firstListRun = True\n",
    "        # print progress\n",
    "        if countries.index(country) % 60 == 0:\n",
    "            print(\"\\tWorking on country: {} out of {}\".format(countries.index(country), len(countries)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[100:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the above dataframe with the real lists from the UN, we see that they do match, although the wine consumption seems a little suspisous to me to be honest. <br /> \n",
    "By [checking this guy here](https://ourworldindata.org/grapher/wine-consumption-per-person) again, they mention that they only record the total alcohol amount of wine. Wine usually has 12% of alcohol in a bottle, thus 1l of wine contains 0.12l of pure alcohol in it. Thus 3l of pure alcohol from wine is the equvalent of approximately 25 bottles of wine. <br /> \n",
    "\n",
    "Hence, the data is accordingly sorted in the right columns and rows and we can go ahead and further analyse this fresh gut here then! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('Entity')['Wine Consumption'].sum().sort_values().tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['Entity'] == 'Germany']['Wine Consumption'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
